# Spark: Day 5
## SparkR vs. sparklyr
- SparkR: SparkR library에서 가져옴
- sparklyr: 패키지 설치, library에서 가져옴

    ```r
    install.packages("sparklyr")
    library(sparklyr)
    ```
    - 스파크 클러스터에 접속할 수 있는 spark 커넥터 사용
    ```r
    sc <- spark_connect(master = "local")
    ```
    - 스파크 클러스터의 초기 환경 설정값 지정
    ```r
    spark_connect(master = "local", config = spark_config())
    ```
    - sparklyr 라이브러리를 사용하면 SparkDataFrame을 무시한다.
    - SQL 코드를 클러스텅서 실행할 수 있다.
    ```r
    library(DBI)
    allTables <- dbGetGuery(sc, "SHOW TABLES")
    ```
    - DBI의 인터페이스를 통해 스파크 SQL과 관련된 전용 속성값을 지정할 수 있다.
    ```r
    setShufflePrtitions <- dbGetQuery(sc, "SET spark.sql.shuffle.partitions=10")
    ```
    - sparklyr는 스파크가 지원하는 다양한 데이터 소스를 활용할 수 있다.
        - csv, json, 파케이 포멧만 지원한다.
    ```r
    spark_write_csv(tbl_name, location)
    spark_write_json(tbl_name, location)
    spark_write_parquet(tbl_name, location)
    ```