# Spark: Day 1
- 교재: [스파크 완벽 가이드 : 스파크를 활용한 빅데이터 처리와 분석의 모든 것]( http://book.interpark.com/product/BookDisplay.do?_method=detail&sc.prdNo=297760736&gclid=Cj0KCQiApt_xBRDxARIsAAMUMu-hL8p3jji-bkW-8aD_tu1rBnYcYzRwqxe2PKN4TM9dqUeaSskqmwMaAv61EALw_wcB)
- 정리자료: https://github.com/ek-koh/medici_bigdata/blob/master/Spark/00.Spark.pdf

## Spark 작동원리
- JVM을 기반으로 돌아감
- 기본 언어는 Scala
- 저장소 역할은 수행하지 않으므로 저장소로 AWS S3를 쓰는지, Hadoop을 쓰는지 등등 확인해야 함
    - 메시지 서비스인 아파치 카프카 요즘 많이 사용

> 라이브러리
- 표준라이브러리: Scala 기반
- 외부 패키지

> 스파크 실행환경
- OS: 윈도우, 리눅스, Mac OS 환경 지원
    - 윈도우는 10 이상 권장
    - 윈도우에서 실행할 때는 파일/폴더 경로 설정 시 공백/한글 없어야 함(Linux 기반이라서)
        - 경로를 JAVA_HOME에 넣을 때 사용함!!


## spark scala로 세팅하기 위한 설정
1. spark 버전과 호환되는 hadoop 다운로드
    - hadoop 2.7 download

2. window에서 hadoop을 실행시킬 때 필요한 프로그램 다운로드
    - http://public-repo-1.hortonworks.com/hdp-win-alpha/winutils.exe

3. hadoop을 실행할 수 있도록 ${HADOOP_HOME}$/bin에 복사하기
    - ${HADOOP_HOME}$ = C:\medici\Hadoop\program\hadoop-2.7
    - C:\medici\Hadoop\program\hadoop-2.7\bin에 복사

4. ${HADOOP_HOME}$을 환경변수에 추가한다.
    - 내컴퓨터 -> 마우스 우클릭 -> 속성 -> 설정변경 -> 환경변수
        - 시스템 변수 설정
            - 변수명: HADOOP_HOME
            - 값: C:\medici\Hadoop\program\hadoop-2.7

5. jdk가 설치된 위치를 확인하는데, 설치된 경로에 공백, 한글, 특수문자 이런 것들이 있으면 문제가 발생할 수 있다(ex. Program Files). 다른 위치로 jdk를 복사하여 공백, 한글, 특수문자가 들어가지 않게 한다.
    - C:\Java를 생성하고
    - C:\Program Files\ojdkbuild\java-1.8.0-openjdk-1.8.0.232-2 폴더를 복사하여 
    - C:\Java\java-1.8.0-openjdk-1.8.0.232-2가 만들어지게 위치시킨다.

6. JAVA_HOME 환경변수 변경
    - 내컴퓨터 -> 마우스 우클릭 -> 속성 -> 설정변경 -> 환경변수
        - 시스템 변수 설정
            - 변수명: JAVA_HOME
            - 값: C:\Java\java-1.8.0-openjdk-1.8.0.232-2

7. java -versioin 실행시켜주고

8. cd C:\medici\Spark\spark2로 이동한다.

9. spark-shell(.cmd)

10. spark> 커맨드가 나오면 spark session이 되는지 확인하기 위해 spark를 작성하고 엔터

## databricks로 환경설정하기
- databricks notebook에서 실행은 `ctrl + enter` or `shift + enter`

## Docker
- docker download and install
- docker tool box 설치
- Window 10 Home에서는 docker toolbox를 설치해야 한다.

> Docker Quickstart Terminal
```
docker run hello-world
docker --version
docker-machine --version
```

> Kitematic (Alpha)
1. 실행
2. use virtualbox
3. 로그인
4. spark_the_definitive_guide_practice 검색 & create (guide까지만 입력)
