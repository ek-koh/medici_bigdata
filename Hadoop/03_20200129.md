# Hadoop: Day 3
## 1. Hadoop Download

## 2. Hadoop Java 만들기
- Properties -> Java Built Path -> Add JARs
    - Add External JARs는 외부의 JAR파일을 가져오는 것. Add JARs는 내부에 들어와 있는 JAR파일을 가져오는 것
![image](https://user-images.githubusercontent.com/58713684/73322199-be5cea80-4287-11ea-90b6-2f9f177b2cf9.png)

## 3. export jar파일 만들기

## 4. jar 실행하기
```
hadoop jar HdfsFile input1.txt "안녕하세요 밥먹으로 가요"
```

### JobTracker(잡트래커)
- 클라이언트가 하둡으로 실행을 요청하는 맵리듀스 프로그램은 job(잡)이라는 하나의 작업 단위로 관리돤다.
- 잡트래커는 하둡 클러스터에 등록된 전체 잡의 스케쥴링을 관리하고 모니터링한다.
- 전체 하둡 클러스터에서 잡트래커는 하나만 실행되며, 하두브이 네임노드 서버에서 동작하도록 구성한다.

### taskTracker(테스크 트래커)
- 사용자가 설정한 맵리듀스 프로그램을 실행하며, 하둡의 데이터 노드에서 실행되는 데몬이다.
- 테스크 트래커는 잡트래커의 작업을 요청받고, 잡트래커가 요청한 맵과 리듀스의 개수만큼 맵 테스크(map task)와 리듀스 테스크(reduce task)를 생성한다.

## 하둡 분산 파일 시스템에서 사용하는 명령어
1. 파일 용량 확인
```
hdfs dfs -du // 파일 사용량을 바이트 단위로 출력
```
2. 파일 용량 확인
```
hdfs dfs -du -s // 디렉토리 전체의 용량만 출력
```
3. 디렉토리 제거
```
hdfs dfs -rm // 디렉토리 제거
hdfs dfs -rm -r // 하위 디렉토리까지 제거
```
4. 파일 복사
```
hdfs dfs -copyFromLocal // 로컬에 있는 파일을 hdfs로 복사
hdfs dfs -copyToLocal // 하둡에 있는 파일을 로컬로 복사
hdfs dfs -cp a b // hdfs에 있는 a파일을 b로 복사
```
5. 파일의 마지막 내용 확인
```
hdfs dfs -tail
```
6. 0바이트 파일 생성
```
hdfs dfs -touch text.txt
```

## 항공 운항 데이터
```
Year
Month
UniqueCarrier
ArrDelay
DepDelay
Distance
```
